---
title: "Computing for the Social Sciences: Lecture 7"
subtitle: "Topics: Data Cleaning, Importing Data, Relational Data"
author: "Sabrina Nardin, Fall 2025"
format:
  revealjs:
    theme: simple
    slide-number: true
    incremental: false
    css: ../style/styles.css
    code-overflow: wrap
    highlight-style: github
    ratio: 16:9
    chalkboard: true
    toc: false
    center: true
---

# Agenda {.center}

::: {.agenda-list}
1. Data Cleaning  
   1.1 Renaming & Recoding Variables  
   1.2 Syntactic vs. Non-syntactic Variable Names  
   1.3 Missing Data  

2. Importing & Exporting Data  

3. Relational Data  
:::


<!--
```{r, echo=FALSE, results='asis'}
cat('<span style="font-size: 0.8em; color: #666;">These slides were last updated on', format(Sys.Date(), '%B %d, %Y'), '</span>')
```
-->

<span style="font-size: 0.8em; color: #666;">
*Slides last updated on **October 20, 2025**. Slides authored by Sabrina Nardin. AI used to polish slides style and fix typos.*
</span>

```{r pkgs, include = FALSE, cache = FALSE}
library(tidyverse)
library(nycflights13)
library(rcis)
library(knitr)
#library(here)
```

<!--
To do: create 3 exam questions for today and 3 for Wed

Mention prep for exam list
1. Review class materials: slides, in-class code, readings
2. Complete HW2 (no AI)
3. Review the in-class prep questions 
4. Ask AI to generate more questions for you (but do it only after previous points, starting from this will backfire)

Add challenge on improving bar chart from scorecard -- say good thinking/problem solving prep for exam
-->

# 1.1 Data Cleaning: Renaming & Recoding Variables {.slide .center .middle}

---

## Definitions

**Renaming**: change variable names (column names)

**Recoding**: change values/levels of categorical variables (column values; e.g., inside a column)

---

## Uses

**When might you need to rename variables or recode their values?**

- You are cleaning data 
  - The variable name has issues: `Flipper Length (mm)` → `flipper_length_mm`
  - You need to standardize values: `"Good"` and `"GOOD"` → `"good"`
  - Etc.
- You are preparing data for modeling or visualization
  - You want to recode `"FEMALE"`/`"MALE"` to `0`/`1` for a regression model  
  - Etc.

---

## We work with the Penguins (raw) Data!

```r
# Load libraries and data
library(tidyverse)
library(palmerpenguins)
data(penguins)

# Explore data
head(penguins_raw)
tail(penguins_raw)
rbind(head(penguins_raw, 3), tail(penguins_raw, 3))
glimpse(penguins_raw)
```

---

## Renaming Variables with rename

To change variable names (column names) the most common method is `rename()` 

Change the name of the variable `studyName` to `study_name`:

```r
# check before renaming
str(penguins_raw)
penguins_raw %>% select(studyName)

# rename
penguins_raw %>% rename(study_name = studyName)   # new = old

# remember to save to keep changes
p <- penguins_raw %>% rename(study_name = studyName)
p %>% select(study_name)
```
---

## 💻 Practice Renaming Variables

- Use `select()` to check the variable `Comments` in `penguins_raw` 
- Use `rename()` to rename `Comments` to `notes`
- Save the result to a new object
- Use `select()` to check again

Once done, copy your code [here](https://codeshare.io/29X3QM){target="_blank"} to share it.

<!--
select(penguins_raw, Comments)
penguins_raw |> rename(notes = Comments)
-->

---

## Recoding Variables Method 1: with mutate + recode

To change variable values (usually levels of categorical variables), we learn two methods. We take the variable `Sex` and turn MALE into 1, FEMALE into 0.

Method 1:

```r
# check before recoding
penguins_raw %>% count(Sex)

# mutate + recode
p <- penguins_raw %>%
  mutate(sex = recode(Sex, "MALE" = 1, "FEMALE" = 0))

# compare
penguins_raw %>% count(Sex)
p %>% count(Sex)

```

<!-- Here we could have unquoted (e.g., `MALE = 1`) but only works if: 
the variable is a factor or there are no spaces or punctuation in the variable name -->

---

## Recoding Variables Method 2: with mutate + case_when

Method 2:

```r
# mutate + case_when
penguins_raw %>%
  mutate(Sex = case_when(Sex == "MALE" ~ 1,
                         Sex == "FEMALE" ~ 0,
                         TRUE ~ NA_real_))
  
# like for method 1 (previous code) save results to keep changes and compare
```

:::{.callout-note}
With `case_when()` each `logical condition ~ value` pair acts like *if → then*:

- for each row, R looks if the condition is TRUE: "*If* you find the value MALE in Sex, *then* convert it to 1"
- `TRUE ~ NA_real_` tells R: “*If* no previous condition was met, *then* return NA as as a number"
:::

---

## 💻 Practice Recoding Variables

- Use `count()` to check the variable `Species` in `penguins_raw` 
- Pick method 1 or method 2 to recode the values of that variable into Adelie, Chinstrap, Gentoo 
- Save the result to a new object
- Use `count()` to verify both results

Once done, copy your code [here](https://codeshare.io/29X3QM){target="_blank"} to share it.

<!--

# Method 1: RECODE

penguins_raw %>% count(Species)

p <- penguins_raw %>%
  mutate(Species = recode(Species,
    "Adelie Penguin (Pygoscelis adeliae)" = "Adelie",
    "Chinstrap penguin (Pygoscelis antarctica)" = "Chinstrap",
    "Gentoo penguin (Pygoscelis papua)" = "Gentoo"
  ))

p %>% count(Species)


# Method 2: CASE_WHEN

penguins_raw %>% count(Species)

p2 <- penguins_raw %>%
  mutate(Species = case_when(
    Species == "Adelie Penguin (Pygoscelis adeliae)" ~ "Adelie",
    Species == "Chinstrap penguin (Pygoscelis antarctica)" ~ "Chinstrap",
    Species == "Gentoo penguin (Pygoscelis papua)" ~ "Gentoo",
    TRUE ~ NA_character_
  ))

p2 %>% count(Species)

-->

---

## The Role of mutate in Recoding

### The dplry verb mutate has many uses: create new columns or modify existing columns values.


:::{.callout-note}
For recoding, we use `mutate + recode` or `mutate + case_when`, because our first goal is changing the *column's values*:

- Method 1: `mutate(Sex = recode(Sex, "MALE" = 1, "FEMALE" = 0))`  
- Method 2: `mutate(Sex = case_when(sex == "MALE" ~ 1, sex == "FEMALE" ~ 0))`
:::

---

## Rename vs Recode: Syntax Reference

<!--
DOUBLE CHECK TIPS WITH REAL R CODE
| Function       | What It Changes    | Syntax + Example                                                | Tips                                                             |
|----------------|--------------------|------------------------------------------------------------------|------------------------------------------------------------------|
| `rename()`     | Column names       | `rename(new_name = old_name)`  <br> `rename(notes = Comments)` | No quotes around variable names                                  |
| `recode()`     | Column values      | `recode(variable, "old" = new)`  <br> `recode(Sex, "MALE" = 1)` | Use quotes around variable values if they are character             |
| `case_when()`  | Column values      | `case_when(variable == "old" ~ new)` <br> `case_when(Sex == "MALE" ~ 1)` | Use quotes around variable values if they are character |
-->


| Function       | What It Changes    | Syntax + Example                                                | Tips                                                             |
|----------------|--------------------|------------------------------------------------------------------|------------------------------------------------------------------|
| `rename()`     | Column names       | `rename(new_name = old_name)`  <br> `rename(notes = Comments)` | No quotes around variable names                                  |
| `recode()`     | Column values      | `recode(variable, "old" = new)`  <br> `recode(Sex, "MALE" = 1)` | Check function doc to see when quotes are needed             |
| `case_when()`  | Column values      | `case_when(variable == "old" ~ new)` <br> `case_when(Sex == "MALE" ~ 1)` |  Check function doc to see when quotes are needed   |


# 1.2 Data Cleaning: Syntactic vs. Non-syntactic Variable Names {.slide .center .middle}

---

## Syntactic (Valid) Variable Names in R

::: {.columns}

::: {.column width="50%"}
### Valid Names in R:
- Use letters, numbers, and the symbols `.` or `_`
- But cannot start with a number or symbol

:::

::: {.column width="50%"}
### Examples of Valid Names:
```r
flipper_length_mm
flipper.length.mm
flipper.length_mm     # valid but poor style
FlipperLengthMm       # valid but poor style
```
:::
:::

---

## Non-Syntactic (Invalid) Variable Names in R

::: {.columns}

::: {.column width="50%"}
### What Makes a Name Invalid:
- Contains spaces or symbols
- Starts with a number or symbol
- Uses reserved words (e.g., `TRUE`, `NULL`, `if`, `function`)
- Type `?Reserved` in the Console for the full list
:::

::: {.column width="50%"}
### Examples of Invalid Names:
```r
Flipper Length (mm)
@_flipper_length_mm
flipper_ length_mm
flipper-length-mm
.flipper.length.mm
```
:::
:::

---

## 💻 Practice: Syntactic and Non-Syntactic Names

Which of the following are valid names?

- `3_religion`
- `#3_religion`
- `q3_religion`
- `q3.religion`
- `q3-religion`
- `q3 religion`
- `TRUE`

:::{.callout-tip}
For best coding style, use snake_case for all your variables names and keep them to three words maximum. Example: `q3_religion`
<!-- Check using `make.names()` in R or try using them in a `select()` call. -->
:::

---

## How to Handle Non-syntactic Names, and Why It Matters

**You should avoid creating non-syntactic names**, BUT you’ll often encounter them,  especially in datasets not created in R (Excel or other sources). If you don’t handle them properly, R will throw errors when you try to use them.

#### What to Do:

**1. Use backticks to refer to them (e.g., `` `Flipper Length (mm)` ``)**  
**2. Use `rename()` to change them to syntactic names**

*Non-syntactic names will break code if you forget to wrape them in backticks, so renaming avoids issues.*

---

## Working with Non-syntactic Names in Practice

Imagine you are working on political ideology by country, assembled by someone else. The data are in Excel and when you imported them in R they look like this:

```r
df <- tibble(country = c("Italy", "Germany", "France", "Italy", "United States"),
                  `4 ideology` = c("communism", "fascism", "anarchism", "fascism", "capitalism"))
```

<br>

To use the non-syntactic variable name without changing it and without errors, you must use backticks:

```r
select(df, `4 ideology`)
```
</br>

---

## 💻 Practice: Syntactic & Non-Syntactic Variable Names

Try this in R:

- Use `glimpse(penguins_raw)` or `str(penguins_raw)` and identify non-syntactic variables names in this raw dataset
- Pick one of them, and try accessing it with `select()` without backticks: what happens?
- Use `rename()` to give the variable a syntactic valid name
- Save the result to a new object
- Verify the name was changed and you can now access it

Once done, copy your code [here](https://codeshare.io/29X3QM){target="_blank"} to share it.

<!--

glimpse(penguins_raw)
select(penguins_raw, `Flipper Length (mm)`)
x <- rename(penguins_raw, flipper_length_mm = `Flipper Length (mm)`)
glimpse(x)


# 1.
select(df, 4 ideology)
select(df, "4 ideology")
# 2. 
rename(df, ideology = `4 ideology`)
-->


# 1.3 Data Cleaning: Missing Data {.slide .center .middle}

---

## What Are Missing Data?

R distinguishes two types of missing data:

- **Explicit missing data**: visible `NA` or `NaN` values in the dataset
- **Implicit missing data**: data that was never recorded

In this course, we focus on **explicit missing data**. For implicit missing data, see [R for Data Science Chapter 18](https://r4ds.hadley.nz/missing-values)

:::{.callout-note}
Explicit = value is missing as `NA` (Not Available) or `NaN` (Not a Number)  
Implicit = value was never recorded (row or cell is absent)
:::

<!--
- `NA` = Not Available (general-purpose missing value)  
- `NaN` = Not a Number (typically from invalid math like `0/0` or `0 * Inf`)  
- Both behave similarly, but `NaN` specifically signals a **computational error**
See [Ch. 12.2.2](https://r4ds.hadley.nz/logicals#sec-na-comparison) for how `NA` behaves in comparisons.
:::
-->

---

## How Missing Data Behave

Any operation involving a missing value will also return a missing value (see [Chapter 12.2.2 Missing values](https://r4ds.hadley.nz/logicals#sec-na-comparison) for more):

```r
NA > 5

sum(c(3, 1, 4, NA)
sum(c(3, 1, 4, NA), na.rm = TRUE)

mean(c(3,1,4,NA))
mean(c(3, 1, 4, NA), na.rm = TRUE)  
```

---

## Common Ways to Handle Missing Data

We’ll review three main tools:  

A. `is.na()` – to detect missing values  
B. `na.rm = TRUE` – to ignore missing values   
C. `drop_na()` – to remove missing values  

<!-- All are for working with **explicit** missing values -->

---

## A. Detect Missing Data with is.na(): 

**Use `is.na()` to find the missing values in a specific variable.** It returns `TRUE` for missing values, and `FALSE` otherwise.

Check for missing values in the `penguins_raw` dataset:

```r
# using base R syntax
sum(is.na(penguins_raw$Sex))
table(is.na(penguins_raw$Sex))

# using tidyverse syntax
penguins_raw %>% summarize(sum(is.na(Sex)))
penguins_raw  %>% count(is.na(Sex)) 

# keep rows where sex is missing
filter(penguins_raw, is.na(Sex))    # correct  
filter(penguins_raw, Sex == NA)     # incorrect

# keep rows where sex is NOT missing
filter(penguins_raw, !is.na(sex))

```

<!-- spend time on this code, add variable names, change df order, etc. -->

---

## B. Ignore Missing Data with na.rm = TRUE 

**Use `na.rm = TRUE` to exclude missing values when performing calculations.** Often used with `summarize()` when calculating things like mean, sum, standard deviation.

```r
penguins_raw %>% summarize(avg_mass = mean(`Body Mass (g)`, na.rm = TRUE))
penguins_raw %>% summarize(sum_mass = sum(`Body Mass (g)`, na.rm = TRUE))
```

<!-- show the difference with and without the na.rm = TRUE and try change it to FALSE-->

<br>

:::{.callout-tip}
The command `na.rm = TRUE` does not remove missing data from the variable(s), it just skips them for that operation, but they are not dropped!
:::
 
</br>

---

## C. Remove Missing Data with drop_na()

**Use `drop_na()` to remove rows with missing values.** Either across all columns or in a specific column.

Drop missing values in one specific column (preferred):

```r
penguins_raw %>%
  drop_na(`Body Mass (g)`) %>%
  summarize(avg_mass = mean(`Body Mass (g)`))
```

<!-- show you can drop_na() all or you can add more variables like 
drop_na(`Body Mass (g)`, Sex) etc. -->

<br>

:::{.callout-warning}
Be careful with `drop_na()` as it removes entire rows, which may unintentionally filter out relevant data. Check which variable(s) you are dropping, and avoid using it blindly across all columns.
:::

</br>

---

## 💻 Practice: Handling Missing Data

0. **Rename:** use the `penguins_raw` dataset and rename `Flipper Length (mm)` to `flipper_length_mm`. Save the result as a new dataframe, e.g., `penguins_clean` or `p` 

Use the new dataframe with the renamed variable for the tasks below:

1. **Detect missing values:** use `is.na()` and `sum()` to count how many are missing in the variable flipper length

2. **Exclude missing from calculations:** use `na.rm = TRUE` inside `mean()` to calculate the average flipper length

3. **Drop missing values:** use `drop_na()` to remove rows with missing values in flipper length

Once done, [share your code here](https://codeshare.io/29X3QM){target="_blank"}.


<!--
# 0. Rename
p <- penguins_raw %>% rename(flipper_length_mm = `Flipper Length (mm)`)

# 1. Detect missing values
p %>% summarize(n_missing = sum(is.na(flipper_length_mm)))

# 2. Exclude missing values from calculation
p %>% summarize(avg_flipper = mean(flipper_length_mm, na.rm = TRUE))

# 3. Drop missing values and calculate again
p %>% drop_na(flipper_length_mm)
-->

---

## Ways to Fill or Replace Missing Data

Main functions to replace or fill missing values:

- `replace_na()` – replace missing values with a specified value  
- `fill()` – carry values forward or backward (from the package `tidyr`)  
- `coalesce()` – return the first non-missing value across multiple columns

See [Chapter 18](https://r4ds.hadley.nz/missing-values) of *R for Data Science* for more.

<!-- NOTE: REMOVE THIS PART FOR CSP, KEEP FOR CSS 
ALSO EXPAND THE EXAMPLE ON HOW TO REPLACE OR REFILL MISSING DATA

## Factors and Empty Groups

Example from [Chapter 18](https://r4ds.hadley.nz/missing-values) of *R for Data Science*.

Create a dataset with with one variable defined as factor with two levels (yes and no):

```r
health <- tibble(
  name   = c("Ikaia", "Oletta", "Leriah", "Dashay", "Tresaun"),
  smoker = factor(c("no", "no", "no", "no", "no"), levels = c("yes", "no")),
  age    = c(34, 88, 75, 47, 56)
)
health
```

---

## Counting with Dropped vs. Retained Factor Levels

Without `.drop = FALSE`, unobserved factor levels are excluded:

```r
health |> count(smoker)
```

With `.drop = FALSE`, all factor levels are preserved (keeps all groups, even those not observed in the data since here they are all non-smokers)

```r
health |> count(smoker, .drop = FALSE)
```

---

## This Matters for Plotting

Compare these two codes.

The default behavior excludes empty levels from the plot:
```r
ggplot(health, aes(x = smoker)) +
  geom_bar() +
  scale_x_discrete()
```

Force display of all factor levels, including empty ones:
```r
ggplot(health, aes(x = smoker)) +
  geom_bar() +
  scale_x_discrete(drop = FALSE)
```
-->

# 2. Importing & Exporting Data {.slide .center .middle}

---

## Importing CSV files

To load data into R we need **importing functions**. There are several of them depending on the **type of file** we want to import. See "R for Data Science" 2nd Ed. Chapter 7 for details.

**The most common importing functions read comma-separated values (csv) files.** Two main versions:

- from **base-R** we have `read.csv()`
- from **[`readr`](https://readr.tidyverse.org/)** we have `read_csv()`

They are similar, but we use `read_csv()` in this course because is more recent, faster, and does not automatically changes data types (e.g., does not convert characters into factors automatically). Type `?read.csv()` and `?read_csv()` in your Console for info.

<!-- `read.csv` is a special case of `read.table`, while `read_csv` is special case of `read_delim`. Look them up to check the differences -- r 
difference between using one ? and ?? in searching for doc
the ? find the exact match
the ?? finds the general match
-->

---

## The function read_csv()

This function takes several arguments, all listed in the [documentation]( https://readr.tidyverse.org/reference/read_delim.html). Some of the most common arguments are:

```r
read_csv(file, col_names = TRUE, col_types = NULL, na = c("", "NA"))
```

**The `file` argument must always be passed, the other arguments can be left as default:**

```r
library(readr)

# load data into my local R Studio, specifying the path
read_csv(file = "/Users/Sabrina Nardin/Desktop/testdata.csv")

# load data into my Workbench, specifying the path
read_csv(file = "/home/nardin/testdata.csv")

# load data (local R Studio or Workbench) without specifying the path 
# where does R look for this file?
read_csv("testdata.csv")

# load data if you are not sure where it is located (not reccomended)
read_csv(file = file.choose())
```

<!--
Make sure the file is located in the given path and you are typing the path correctly. Let's practice!
-->

---

## 💻 Practice: Load Data in R

1. Create a `testdata.csv` file with four columns (id, name, age, food) with different data types and some missing data. Save it on your desktop with a `csv` extension.

1. Open Workbench: upload the file to the server. Skip this step if you are using R on your machine.

1. Look at your current working directory by typing `getwd()` in the console. That's where R looks at files by default.

1. Load `library(tidyverse)` and import the data into R using `read_csv()`. If you do not provide a path, R looks in your working directory.

---

### Changing Default Arguments

In the next slides, we are going to modify some of the most common arguments of the `read_csv()` function. 

Let's start by using the function without modifying them, by simply typing `read_csv(file = "testdata.csv")`

What do you notice? 

<!--
This file is a good example of messy data!
type of column is shown at the top, e.g. id is double, name is char, but so is age, which should not be. Why so? the "na" is interpret as a character rather than missing data and all column values are forced to character.
-->

---

### Modify the col_types argument

The default is `read_csv(file, col_types = NULL)`. We can change it to manually set the column types, as shown below (two options):

```r
# option 1
read_csv(file = "testdata.csv",
         col_types = cols(id = col_integer(),
                          name = col_character(),
                          age = col_integer(),
                          food = col_character()))
# option 2
read_csv("testdata.csv", col_types = ("icic"))
```

Pick one option, and run the code in your Console to re-import the data. What do you notice?

<!-- all columns types have been converted to the datatype we specified. R is also guessing that the na in age is actually missing data and so converts it as such, but we get a warning message; type problems() to see more
-->

---

### Modify the na argument

The default is `read_csv(file, na = c("", "NA"))`. We can change it to add more missing data options, like that:

```r
read_csv("testdata.csv", col_types = ("icic"), na = c("", "NA", "na", "None"))
```

What do you notice? You can customize what goes into the vector `c()`

<!-- we can enlarge the set of missing data to include everything we want -->


---

### Modify the col_names argument

The default is `read_csv(file, col_names = TRUE)`. We can change it to `col_names = FALSE`, like that:

```r
read_csv(file = "testdata.csv", col_names = FALSE)

```

What do you notice?

<!-- first line is not more read as variable names -->

---

### Modify the skip argument


The default is `read_csv(file, skip = 0)`. We can change it to `skip = 2` or any to any other integer.

```r
read_csv(file = "testdata.csv", skip = 2)

```

What do you notice?

Useful when your data contain problematic rows. Note that `read.csv()` (base R) doesn’t support this option. If skipping lines doesn’t work, make sure you’re using `read_csv()` from `readr`

---

## Takehome

Importing files correctly is important as it prevents problems that might emerge later!

Check the function arguments: there are many of them available that can help you accomplish almost anything you need!

*Let's clarify a few additional concepts related to importing and exporting data...*

---

## Working Directory

The working directory is the folder that R takes as **default directory** every time you try to load a file, script, etc.

To check your current working directory: start a new session of R and type `getwd()`. In Workbench it should be `"/home/your_cnetid"`

---

## Relative Path vs. Absolute Path


When you import a file (for example, from the *Workbench “Files” tab*) into R, you should use a **relative path** instead of a **full (absolute) path**.

::: {.columns}

::: {.column width="50%"}

### Relative Path  

- Means relative to your R project folder (the one containing your `.Rproj` file)  
- Recommended approach: easier and makes your code portable  
- Works only if the file is inside R’s default working directory  

```r
read_csv("testdata.csv")
```

:::

::: {.column width="50%"}

### Absolute Path  

- Means you specify the entire path to reach the file, independent from specific folders  
- Avoid this: it breaks if someone runs your code from another machine or folder  
- Independent on R's default working directory  

```r
read_csv("/home/nardin/testdata.csv")
```

:::

:::

<!--
You can also manually set your directory to an absolute path, for example using `setwd()` but that is not the best approach for reproducible. Use relative paths instead!
-->

---

## Easier Solution: Use RStudio Projects

::: {.callout-tip}

### RStudio Projects `.Rproj`

RStudio Projects automatically set the working directory for you, based on the active project:

- ensures portability across computers and a reliable behavior!
- you do not need to set the working directory manually
- but you need to check in which project you are working

:::

**Example:** Each *homework* and *in-class exercise* folder in this course contains a `.Rproj` file. When you open that project in RStudio, the working directory is automatically set to that folder.

**Tip:** If you switch to another project, RStudio automatically updates the default working directory for you. Always check which project you’re working in.

<!-- for HW3, released tmr, we are asking to load data, we will be giving you a rproj like in HW2, so all you have to do to load teh data is to be in the correct project and then use a relative path with the name of the data.csv
-->

---

## 💻 Practice: Create an RStudio Project

Step 1: Open RStudio and navigate to the top-left menu. Then File > New Project...

Step 2: Choose New Directory, then select New Project

Step 3: Name your project and save it.

Step 4: Click Create Project. RStudio will open a new session within your project environment. Done!

Step 5: Let's test it! In your new project, create a new R script or R Markdown document and inside it type and run `getwd()`. What do you notice?

---

## Other readr functions to import data 

The `readr` package include several functions to load into R almost all possible file formats that you might encounter (when given an option though, choose a `csv` over other formats). 

For example:

* **Comma separated csv** use `read_csv()` from the `readr` package
* **Semi column separated csv** use `read_csv2()`from the `readr` package
* **Tab separated files** use `read_tsv()`from the `readr` package
* **RDS** use `readRDS()` or `read_rds()`
* **Excel** use `read_excel()` from the `readxl` package
* **SAS/SPSS/Stata** use the `haven` package (several functions)

Cheat Sheet for `readr`:
**Help > Cheat Sheets > Browse Cheat Sheets**

---

## Using haven with SAS

```r
library(haven)

read_sas(data_file = system.file("examples", "iris.sas7bdat",
  package = "haven"
))
```

---

## Using haven with SPSS

```r
read_sav(file = system.file("examples", "iris.sav",
  package = "haven"
))
```

---

## Using haven with Stata

```r 
read_dta(file = system.file("examples", "iris.dta",
  package = "haven"
))
```

---

## Exporting data with write_csv()

So far we talked about **IMPORTING DATA** with `read_csv()` from `readr`

But`readr` has also several functions for **EXPORTING DATA**. The most common is `write_csv()` which **generates csv files from R data frames**: https://readr.tidyverse.org/reference/write_delim.html

```
# import
test <- read_csv("testdata.csv", col_types = ("icic"), na = c("", "NA", "na", "None"))

# write your data analysis and visualization code etc.

# export 
write_csv(test, file = "testdata_cleaned.csv")
```

# 3. Relational Data  with dplyr {.slide .center .middle}

---

## Definition of Relational Data

**Relational Database:** set of multiple "tables" that are linked based on data common to them. You can think of a "table" as a dataframe.

**These tables provide meaningful insights only when combined together!**

Answers to research questions are not defined by individual rows or columns in a single table; rather, they emerge from the relationships among tables.

<!--
why you want to do so? e.g. store data in different tables?
Data you need for the analysis is not and cannot be stored in one single table but it is split across tables; usually two but potentially more
-->

---

## Our Focus

There are several software and languages to deal with relational databases. The most common is SQL but that's beyond our course. For more on this, see ["Chapter 21 Databases"](https://r4ds.hadley.nz/databases) from our book.

**R also allows you to join tables using the `dplyr` package. That's our focus!**

<!-- dplyr for relational data focuses on joining tables; it is basically merging data and no really needing sql terminology and concepts (e.g., table, attributes, relations) but there is value in using them, as explained in the assigned readings from today, which is Ch 19 joins from the book

So we do a mini theoretical intro to relational databases logic and terminology and then we move to dplyr
-->

---

## We use the flights example from the readings

`library(nycflights13)` in ["Chapter 19 Joins"](https://r4ds.hadley.nz/joins) from "R for Data Science" 2nd Edition. 

We have five tables (e.g., five distinct datasets):  

* `flights` info about flights, identified by multiple variables  
* `airlines` each airplane company name, identified by the abbreviated `career` code  
* `airports` info about each airport, identified by the `faa` code  
* `planes` info about each plane, identified by its `tailnum` number  
* `weather` info about the weather at each NYC airport for each hour, identified by various variables  

Load the data into R (package already installed on Workbench): `library(nycflights13)`

---

## We use the flights example from the Readings

Visual representation of the relations among the 5 tables in `nycflights13`:

```{r out.width="60%", echo = FALSE}
include_graphics(path = "07-pics/relational-nycflights.png")
```

To understand diagrams like this, remember that each relation concerns a **pair of tables**. 

---

### Formal definitions 

A **KEY** of a table is a one or a subset of columns (formally called "attributes"). Two types of keys:

* **PRIMARY KEY**
uniquely identifies an observation in its own table; e.g., `tailnum` is the primary key of the `planes` table; a primary key can be one or multiple columns.

* **FOREIGN KEY**
matches the primary key of another table; e.g., `tailnum` is a foreign key in the `flights` table (it links each flight to a unique plane by matching the tantalum primary key from the planes table

<!--
A variable can be both a primary key and a foreign key. For example, origin is part of the weather primary key, and is also a foreign key for the airports table. 
-->

A **RELATION** is defined between **pairs of tables**: primary key + foreign key in another table.

<!--
Relations can be
* one-to-one
* one-to-many: each flight has one plane, but each plane has many flights
* many-to-many
-->


---

## In pratice... when using dplyr to work with relational data, we have:

### 1. Mutating joins

### 2. Filtering joins

---

## 1. Mutating joins

This group includes:

- **inner join**: keeps observations that appear in both tables

- **outer join**: keeps observations that appear in at least one of the tables  

  * **left join**: keeps all observations in left table  
  * **right join**: keeps all observations in right table  
  * **full join**: keeps all observations  

---

## inner_join()

Keeps obs. that appear in both tables, identified by keys (colored numbers). Unmatched rows are dropped.

::: {.columns}
::: {.column width="45%"}
![](07-pics/join-setup.png){width=90%}
:::

::: {.column width="55%"}
<br>
<br>
![](07-pics/join-inner.png){width=100%}
</br>
</br>
:::
:::

<br>

```r
# inner_join example
inner_join(x, y, by = "key")

# with pipes
x %>% inner_join(y, by = "key")

# if the join columns have different names
inner_join(x, y, by = c("a" = "b"))
```

</br>

<!-- by convention, x is assigned as the first dataframe or left one, and y as the second or right one; 

the by argument specifies that we are joining it based on the key column (which you cannot see from the slide but its the column name of the colored columns in each x and y). Compare this to the left_join() operation which is another form of mutating join
-->

---

## left_join()

Keeps all obs. in the left table (x), even if there is not a match in the right table (y).

::: {.columns}
::: {.column width="45%"}
![](07-pics/join-setup.png){width=90%}
:::

::: {.column width="55%"}
<br>
![](07-pics/join-outer-left.png){width=100%}
</br>
:::
:::

<br>

```r
left_join(x, y, by = "key")
```

</br>

---

## right_join()

Keeps all obse. in the right table (y), even if there is not a match in the left table (x).

::: {.columns}
::: {.column width="45%"}
![](07-pics/join-setup.png){width=90%}
:::

::: {.column width="55%"}
<br>
![](07-pics/join-outer-right.png){width=100%}
</br>
:::
:::

<br>

```r
right_join(x, y, by = "key")
```

</br>

<!-- same thing as left join but reversing the order of the data frame or table
typically right join is utilized less because by convention we think at the left or x table as the primary  data for these kind of operations 
-->

---

## full_join()

Keeps all obs., matches and non-matches (e.g., more missing values).

::: {.columns}
::: {.column width="45%"}
![](07-pics/join-setup.png){width=90%}
:::

::: {.column width="55%"}
<br>
![](07-pics/join-outer-full.png){width=100%}
</br>
:::
:::

<br>

```r
full_join(x, y, by = "key")
```

</br>

---

## Venn Diagram 

```{r out.width="60%", echo = FALSE}
include_graphics(path = "07-pics/join-venn.png")
```

---

## Filtering joins

Other than mutating joins, `dplyr` has filtering joins;

- **semi_join**: keeps all observations in x that have a match in y
- **anti_join** drops all observations in x that have a match in y

Essentially these function use information from the second data frame (y) to filter observations from the first data frame (x).

---

## semi_join()

Keeps all obs. in x that have a match in y. Only keeps columns from the first table you pass in the code (x).


::: {.columns}
::: {.column width="45%"}
![](07-pics/join-setup.png){width=90%}
:::

::: {.column width="55%"}
<br>
<br>
![](07-pics/join-semi.png){width=100%}
</br>
</br>
:::
:::

<br>

```r
semi_join(x, y, by = "key")
```
</br>

---

## anti_join()

Drops all obs. in x that have a match in y. Only keeps columns from the first table you pass in the code (x).


::: {.columns}
::: {.column width="45%"}
![](07-pics/join-setup.png){width=90%}
:::

::: {.column width="55%"}
<br>
<br>
![](07-pics/join-anti.png){width=100%}
</br>
</br>
:::
:::

<br>

```r
anti_join(x, y, by = "key")
```

</br>

---

## 💻 Practice working with relational data with dplyr

Download today's in-class materials from the website (`relational-data.Rmd`)

---

## Recap: What We Learned Today

- How to rename variables using `rename()`
- How to recode values inside a variable using `recode()` and `case_when()`
- The difference between syntactic and non-syntactic variable names, and how to handle them
- How to detect, ignore, or drop missing
- How to import data with `read_csv` and export data using `write_csv`
- How to work with relational data using `dplyr`

---

## To print these slides as pdf

Click on the icon bottom-right corner \> Tools \> PDF Export Mode \> Print as a Pdf
